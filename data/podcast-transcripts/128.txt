00:00:00,120 --> 00:00:18,400 [Speaker 0]
Hey, everyone. Thank you so much for watching another episode of the Weaviate Podcast. I'm super excited to welcome Charles Pierce, Director of the Weaviate Labs team. We've recently announced the GA release of the Weaviate Query Agent. I'm super proud of this. I think we have a really compelling agent in production, agent product story, and I'm just super excited to dive into it further. Charles, thank you so much for joining. 

00:00:18,480 --> 00:00:23,980 [Speaker 1]
Connor, it's great to be back. I think it's, uh, my f- fourth, and a half- 

00:00:23,980 --> 00:00:24,890 [Speaker 0]
[laughs] 

00:00:24,890 --> 00:00:32,980 [Speaker 1]
... um, appearance on the podcast after the last one was cut short due to, to technical issues. But yeah, it's great to, it's great to be back. Um- 

00:00:32,980 --> 00:00:33,700 [Speaker 0]
Yeah. 

00:00:33,700 --> 00:00:41,600 [Speaker 1]
I'm, I'm really looking forward to talking about, um, the Query Agent and how the last couple of months of development have looked. 

00:00:41,600 --> 00:01:12,300 [Speaker 0]
Yeah, I think this is our 128th podcast, but if I had to take halves for every time I've had, like, the [laughs] MacBook audio pickup or have my camera out, I think I'd be at, like, 124 or so. But, uh, yeah, awesome. Well, so the GA release of the Weaviate Query Agent, um, maybe even before diving into the tech, I think something that, that you do exceptionally well at Weaviate, in your role with the Weaviate Labs team is, not only running our team, but also coordinating across multiple teams from, say, Alvin to Paul, Esbasion, Seb, Bob. Uh, could you maybe describe sort of the collaborations within Weaviate behind the Query Agent? 

00:01:12,300 --> 00:04:11,180 [Speaker 1]
Yeah, absolutely. Well, like, you know, the, the, the Query Agent is built by, you know, our team, the, the Labs team, um, but, you know, it's, it's just a component that it... in order to make it work seamlessly as part of, like, the, the Weaviate ecosystem, um, I think it needs, like, an- a lot of collaboration to, to get, to get to that point, to make it feel seamless. Um, and I think one of the best things about working at Weaviate is how willing and open people are to, to work, work together to get something over the line. So, you know, while we might have kind of... Our team might have technically been working on, like, the technical development, development of the Query Agent, so much goes on in terms of collaboration to make this work, you know, from working with Weaviate's console team to... over the last couple of months to get the Query Agent in there in like a, in a native experience was a, a huge amount of, a huge amount of work. Um, and even just, you know, making... The way that we make the Query Agent work kind of so... and authenticate so magically with the console is because of the work we do with that team. And, you know, you have... We work very closely with the product team at Weaviate to, especially over the last couple of months, to actually interview and talk to users of the Query Agent to get feedback on what they thought was working, what they thought was missing and n- not working really so well. Um, and those conversations were, like, incredible to me because... And I... They were... I always really enjoyed going to them because the amount of unexpected things you would discover was just incredible. Like, you know, seeing, watching people use it and it's like, "Oh, that's not what I expected you to do, but it's, it's really interesting." So we learned so much from that. Um, and then you have things like, you know, the, the people that interact with the, with the Query Agent through a client. So we need to integrate with, like, the clients. So that means that we work with the core team, um, on, on that element to make sure that the, the client experience, even though it's like the Query Agent is officially like a different service, that that feels seamless as well. Um, and then there's how we communicate about, uh, the Query Agent. So that kind of covers from all the way from documentation, which is fantastic and really clear, all the way over to, you know, how we post about this and build excitement and, like, let our... let people that follow us know what the, what the Query Agent is and what use cases and problems it can solve for. So I love working, um, with other teams, and I think it's like, you know, it's pretty impossible to, to not... You know, it's, you, you can't be successful without collaborating well, I think. In, in, in that sense, that's for most companies, right? You know, you can't silo yourself off. So we really depend on, on kind of collaboration. And, um, yeah, it's great to have another kind of launch over the line as a result of that great collaboration. 

00:04:11,180 --> 00:04:25,860 [Speaker 0]
Yeah, that's amazing. Yeah, uh, just super cool, super awesome to see everyone coming together and working on this. And, yeah, so awesome. Well, to warm up into the tech, uh, can you maybe, uh, give sort of the elevator pitch for the Weaviate Query Agent for people who are new to, n- new to what it is? 

00:04:25,860 --> 00:05:04,620 [Speaker 1]
Yeah, absolutely. So, the way I think about the, the Query Agent is that it's like your domain expert at utilizing Weaviate, utilizing its APIs, knowing how to, you know, squeeze the most functionality out of Weaviate, um, for you, that works for you. So it's effectively like kind of a next generation interface, that... to databases, that happens to be an agent, and you just talk to it in natural language, and it will do everything it can in the background to answer that question or retrieve results for you in the best possible way. 

00:05:04,620 --> 00:05:26,020 [Speaker 0]
Yeah. Awesome. And maybe just to kind of... You mentioned like sort of the lessons learned from talking to cus- talking to users and, and that kind of like, um... totally new things you hadn't thought about originally until you started seeing people trying to use it. Um, maybe just sort of the journey of like the initial beta release to now GA. I think the timeline is about like six months or so. Just what has that kind of been like? 

00:05:26,020 --> 00:08:22,652 [Speaker 1]
Yeah, so I think like in March we released the, the Query Agent in preview, like an alpha launch. And it was... It's been free, open to, open to all, uh, Weaviate Cloud, uh, users, whether they're sandbox or paid. And effectively during this period, we just wanted to let people use it. And, you know, for those that were using it a lot, we might reach out and ask what you think, get some feedback. And kind of, like, the experience here was that we saw that there were certain use cases that were like really sticky with people coming back and, and using it a lot. Um, so we would interview them or have, have conversations and...... some of the... Effectively, like, what we were trying to, like, hone in on in these conversations was n- not, l- like, we would talk about it s- up- upfront, like, "Oh, what's working?" But really, what I was really interested in was, like, what's not working or, like, what's not meeting your expectations? Um, and there was, like, a few things that, like, came up there that, like, broke my expectations of how people wanted to use the query agent. And I think, like, you know, speaking more broadly on, like, product development, I think it's, like, everyone aims to be, um, objective when they're, like, building- building products and stuff like that. But it's... I... Like, it's very hard to be, like, purely objective. So, like, you- you make design decisions, like I did, that were kind of like what- how I would use it. And then that's- that's not what I always saw. So for example, one thing that wasn't there when we launched was, like, a very kind of simple and standardized, like, chat functionality. So pretty much users weren't able to, like, really power, like, kind of like a chat application. It was kind of the intended functionality initially was just you type a query and get, like, an answer back. And then that... it's like a one-off type thing. And you could pass in a little bit of prior context, but the assumption was that, oh, there won't be... Like, you know, we don't want to be a chat app or anything like that. But then I saw what... how people were building with it, and they were building it into- into chat applications. And I was like, "Okay, so people want to be able to have this option to- to do the one-off kind of query mode", like we had where it does your query, does your filters, gives you back an answer. But they also wanted the ability to put that into a chat context. And because we didn't build that initially, users were being creative in working their own way around it. Um, but we made the decision as part of the GA launch to, like, kind of revamp all of that interface and allow both the options for just passing a query or passing, like, a conversation history that updates over time, um, as well. Um, and then probably the- the biggest one, the biggest thing that, you know... I i- imagine we'll chat about in this conversation, but the- the biggest kind of thing that I noticed some users were doing was that, 

00:08:22,652 --> 00:09:53,632 [Speaker 1]
uh, the original query agent run mode, as we called it, um, was very much designed to be, like, end-to-end. So it would take your query, route that to the right collections, um, because it can do multi-query, uh, multi-collection routing, break those queries up into constituent queries, you know, query expansion. All of this, we- we worked on it. Um, and then it would also write the answer for you. But I realized that there's a bunch of users that they really liked it for, like, its... all of its features up until the generative part. But some- some users actually wanted to build, you know, their own... U- use it as, like, a component, a retrieval component that then gets passed to some other agent or some other feature or some other functionality. So they really didn't need that, like, what we call, like, the evaluation step or the answer writing step. But they really liked the- the ability o- for the retrieval, like agentic retrieval effectively. So rather than then what a lot of these users were doing was that they were, you know, running the query agent, getting the- getting the answer, throwing that away, and just using the sources that were returned by it. So they just liked it for the sources. So, um, as you know, like, we kind of, like, kind of the team kind of banged our heads together and were like, "Well, maybe we should just build in a full retrieval search mode that, you know, just skips- skips the generation part." But then we would really, like, refine the quality of, like, the- the retrieval results and make sure that you can effectively have 

00:09:53,632 --> 00:10:21,572 [Speaker 1]
an experience that feels like you're just querying in Weaviate. But when you look at the results, they're, like, really, really, like, tuned to what you said and they can- can capture both the- the fuzzy and, um, structured parts of your query. And then we can still power multi-collection search. We can re-rank across multiple collections, all of this kind of stuff. So that's- you know, that's where we got the idea for search mode, um, from. Um, and that's also now live as part of this GA launch. 

00:10:21,572 --> 00:10:51,182 [Speaker 0]
Yeah, it's super interesting. There's so many, like, axes to this to sort of zoom into further. I think, like, just kind of listening to it, like, if I was outside the walls of Weaviate, this sort of, like, lesson I'm maybe... Like, maybe just to begin talking to people who are building their own agents, this kind of like, you come up with these different in- inferences and you're stitching together these inferences. And- and then you're sort of saying, "Oh, I need to adapt it this way. It needs to actually have these output models," or even have, like, an exit path. In this one system I have can do multiple things. And yeah, that's- 

00:10:51,182 --> 00:10:51,182 [Speaker 1]
Yeah 

00:10:51,182 --> 00:10:52,452 [Speaker 0]
... our design now. 

00:10:52,452 --> 00:11:29,271 [Speaker 1]
It's- it's probably like the- the other big lesson of the last six months of development, is that, like, um, with agents, and I think this is like probably... I think many people that work in agents, like, kind of building, like, very domain-specific agents, would probably echo the same thoughts. But getting up and running nowadays with agents has gotten, like, pretty smooth. Like, you can- you can do it with code, but you can do it through an interface as well, using N8n, all of these really nice kind of agentic workflow builders. Um, but 

00:11:29,271 --> 00:12:34,087 [Speaker 1]
what I've learned is, like, it's... You can get to- you can get to the point where it works in broad terms, like end-to-end, like relatively fast, but making it, like, an expert user and, like, catching all the edge cases. And I think edge cases is, like, the key word, because there's so many edge cases, um, and you have to account for all of that. And that- that's like... Probably 80% of the work, you know, in broad strokes, was done around March. But then in terms of getting it to be, like, really, really good and high quality, that's- that's what takes time. And it's still something, like, we're always going to be working on that because, you know, u- users will always ask questions that, like, raise an edge case or something like that, or kind of demand another piece of functionality. So with- with agents...I think the barrier to entry has become quite low, but the- the groundwork and the hard work and this, like, the elbow grease is still required to get it to, like, that expert level. And I think that- that's probably true for- for many different types of systems, whether it's a database or some other type of interface to another type of system. 

00:12:34,088 --> 00:13:13,988 [Speaker 0]
Yeah. That's interesting, and I'll definitely probably ask you for a hot take on evals at the end, and people- uh, people who watch the podcast know I have chapters, so you can skip to that now if you want. But, uh, I wanna really come back to kind of, yeah, the sort of refinement, and you described it, and kind of maybe setting the stage with the design of the product and the kind of... I wanna talk about the Python and TypeScript clients a little bit. Just, like, how you think about sort of... Maybe inside Weaviate I've seen how you think through, like, response models, and I think it's one of the most interesting things of... Just in my experience, I've learned a lot of software engineering from Weaviate and seeing how software engineers work. And sort of just discussing maybe, like, how- how you think about the response models that are returned from the query agent, the arguments to the- to the clients. How- 

00:13:13,988 --> 00:13:14,288 [Speaker 1]
Yeah. 

00:13:14,288 --> 00:13:15,508 [Speaker 0]
What goes into that? 

00:13:15,508 --> 00:13:26,288 [Speaker 1]
So, like, the- the- the whole- the whole, like, ethos for me with the- in terms of the clients and, like, the interface to them was that 

00:13:26,288 --> 00:16:33,108 [Speaker 1]
the goal here is, like, reducing workload and, like, making things simple. So, for a user that wants to just run the query agent out of the gates, it should be possible to just create a query agent instance and just type a natural language query, however they want to structure that, and run it- r- run it against Weaviate in, like, two lines. You know, that's what it takes. You can- you have your constructor, and then you run it. Um, and of course, there's ways of, like, kind of configuring it that will add more lines of coding, but that experience does exist where you can do that. So the whole idea is that, you know, this- th- this is an agent, so it's supposed to be, like, reducing the amount of- the amount of manual work you're doing, whether it's filters, tenants, al- all of these types of things. It's supposed to be, like, a simple interface. So in terms of how you communicate with the query agent, that's really important, like, just simplicity, because that's- that's what we're aiming to solve for developers, a sim- a simpler interface to databases. Um, and then in terms of the response model, it's like- it's almost- not the opposite, but it's- it's definitely an idea of, well, the user has, like, given over control to this agent to do something for them that they would have done manually in the past. So, I'd never thought that just giving an answer or a set of results was, like, um, like, that's all you need to do and just say, "Trust us." I think, like, the- the idea behind, like, how the response model is shaped and stuff like that was, like, also a big part of it, was just building trust, um, wi- with the users. So, we kind of- we have, like, an audit trail, effectively, in the- in the response model. So you have your answer or you have your search results if you're just doing search mode, but you also have things like, uh, like, uh, a formatted list of the actual searches that were run. So you would have given the query agent a natural language query, but the- the questions or the- the queries that were run against the database very likely were transformed somewhere along the way. So it's imp- what we do is we return the actual queries that were run against the database, um, by the agent back to the user. So if they need to, they could effectively, like, recreate the queries if- if they wanted to against the database manually themselves to- to see. Um, and then you- you have... It's the same for aggregations. And we also include, um, kind of an- an interesting field, two interesting fields. One which is like a Boolean, like, is this a partial answer? And then missing information. Um, and the idea there was just... This is, like, from my own experience. Like, I've kind of been toying in and out of explainable AI for a couple of years, and with LLMs, it's- it's a little bit different t- to how explainable AI works with, like, kind of the older- older style, like, BERT models where you do, uh, per- perturbation. But the idea here was still to make this, like, an explainable AI system. Um, so effectively, we give th- the model- the- the models will write an answer to your question, 

00:16:33,108 --> 00:18:37,679 [Speaker 1]
but there's this optional field for missing information. And the whole idea there is just that if you wanted to have some sort of safeguard in your- if you're building, like, a system, and you wanted to have some sort of safeguard to alert downstream end users that, "Oh, this answer might not be fully comprehensive," or- or something like that, now there's, like, a direct field that you can, like, assert, like, is true and whether it exists. And if that's the case, you can... It- it allows, like, kind of developer-designers to develop an experience where they say, "Here's your answer, but also, just so you know, um, we can tell that maybe something's not... We couldn't find something in your database to, like, fully answer this or fully motivate the answer," or something like that. So, um, the agent is- the- the query agent is, like, effectively, like, a little bit, like, explainable i- in- in- in that sense. Um, and then, of course, like, we have sourcing, because the, like, the query agent is- it- very much grounded in the data from your collections. So it's, uh, any kind of answers and stuff like that it gives and/or results get that it gives should be, you know, sourced from the database. It shouldn't be hallucinating. It shouldn't be kind of making up answers, um, if- if something doesn't exist. So we make sure to, as part of the re- response model, actually, especi- this is for ask mode, um, to return the- the collect- the objects and collections to which they belong, which- so that, you know, a- again, as part of, like, a- a building, like, an end-to-end product with it, someone could build a- a- a gooey application that shows the answer, um, and actually shows the- the objects that kind of inspire that answer, I guess. And we do this in the- in the console- console version of the query agent as well.... it utilizes that feature. Um, and of course, for search mode, it only returns answers, so th- that wasn't as much of a problem, but for ask, what we call ask mode now, um, it was really important. That, that's something we've, we've made that better over time as well, how, how it sources. 

00:18:37,679 --> 00:19:51,240 [Speaker 0]
Yeah, I think that just general topic of having this rich response from an agent API is so interesting and, yeah, maybe d- uh, diving into these two thing- I mean, obviously you'd expect the final answer, but then also having the structured searches and aggregations behind the sort of like, you know, text SQL with search, that's kinda how I just think about this, is like, it's got, i- it's not just text SQL 'cause we're also adding this kind of search operator, but this is like one way maybe to think about it anyways, but, yeah, that, that kind of explainability thing is so interesting maybe. This is my first time I'm referencing my dad on the podcast, but he works at, uh [laughs]... After 128 episodes, he's finally gonna get a reference [laughs]. But I... Is it... So, he works at Quest Diagnostics, and I, I was curious asking him what he thinks about AI, and for him, it, like, that kind of explainability is a huge thing for them. They can't, like, give you just like a AI interpretation of your blood test results, like, so I think that kind of explainability, that m- partial answer missing information, I really love that. And then, yeah, that kind of citations. I... Maybe... Yeah, I don't know how, like y- maybe diving in further to the citations thing, I'm just kinda curious about, yeah, what you think about the kind of hallucinations in citations, is... Do you think citations just kind of solves... I know this is kind of taking a little bit of a detour. Just- 

00:19:51,240 --> 00:19:51,250 [Speaker 1]
Yeah 

00:19:51,250 --> 00:20:07,899 [Speaker 0]
... really interested in these topics, but, yeah, like, how much do you think citations sort of limits... Like, when you get an answer back and it's got citations, I think that sort of takes the bur- like, I think one of the big criticisms of AI is, oh, it might hallucinate, and that sort of puts you off of it maybe, but this sort of citations thing seems like the solution. 

00:20:07,899 --> 00:21:31,500 [Speaker 1]
Yeah. I, I think s- that's a really cool question, 'cause like, I think cit- citations is like... I'm not gonna just say it's like the perfect, it's like absolutely, you know, bulletproof, and like that's, that's the o- that's like kind of explainability solved. Um, but we had like two, two interesting things that I learned, like, from this was that initially when we did the citations, we actually had the answer, um... And you know this. We had the answer on the citation kind of written in the same step by like the same process effectively. Um, that doesn't happen anymore. Now it, they kinda happen sep- they kinda happen separately where the answer is constructed and then we like kind of independently get this s- citation kind of, uh, tool call or agent call happening on, on that answer. And I think that like improves the adherence a little bit to like truly cite, cite, like citing, because the citations aren't primed by like the, the answer writing as much. Um, but... Kind of going back to your question, like, I don't think... You can't like... Citations aren't ever gonna be perfect either because you are dealing with an LLM under the hood, so in, in some instances it might just want to pa- take the path of least resistance and just find something in there to, to cite. So like that's always possible. Um, probably like if you really wanted to go very rigorous with this, what you could do 

00:21:31,500 --> 00:21:37,939 [Speaker 1]
is like make the citation step itself, like its own kind of multi-layered agent, where like it c- 

00:21:37,939 --> 00:21:38,659 [Speaker 0]
[laughs] 

00:21:38,659 --> 00:21:42,379 [Speaker 1]
... it can, like, really kind of go into like a loop 

00:21:42,379 --> 00:22:51,419 [Speaker 1]
and, you know, like, kind of prod, prod the questions and poke around and be like, "Let's actually like, let's, let's look at each source individually and really like test how relevant it is to the, the actual answer that came back." But I would say like for the majority of, majority of the use cases, the way we do it now is probably acceptable, but yeah, like if... Probably if, if you're doing something like, oh, I don't know, something in like a medical domain or something like that, you might want to be... Or like if you're kind of using it to do like very kind of mission critical sourcing or something like that, you might want to like make that citation a little bit more like rigorous or something like that. Um, but yeah, I, I mean, a lot of people do it nowadays. Um, and it's... I think it's almost, it's almost seen as like kind of like a, a standard kind of response format for like, for these applications. I mean, ChatGPT, uh, Claude, they all have it now built into the... When you use their, their systems, you know, you, you, you use it and you see, like you see like the nice web links and all that kind of stuff that were, that were brought back. So 

00:22:51,419 --> 00:23:01,480 [Speaker 1]
basically my answer is, it probably works for the majority of use cases, but there's always gonna be like a, a few cases where maybe the LLM just, like I said, takes that path of least resistance. 

00:23:01,480 --> 00:23:38,050 [Speaker 0]
Yeah, I think that's a pretty deep one. Uh, even just like when I'm talking to ChatGPT with, uh, say, deep research and it's citing sources and I'm like, "Oh, it's... that's the source you're using?" Like, you know, you wanna sort of [laughs]. And so this kind of bring your sources... Uh, the... I mean, obviously that's kinda generally a big setup to this, but yeah, such a deep topic. Um, so, awesome, so one other kind of topic I wanted to touch on sort of as we're kinda diving into the features of the creation and how it works is this kind of like, um... I think this sort of schema introspection thing is one of the most interesting things as you're talking about database companies like Weaviate that co-design agents with their database. Uh, can you maybe talk to that, just like, yeah? W- 

00:23:38,050 --> 00:24:10,399 [Speaker 1]
Yeah, absolutely. So like, the, the great thing about building an agent for a database is that you're working with a database. So databases are, you know, strongly typed. Um, they have different fields, they have different property types that can be created. And because of that, and because we are, you know, the, you know, we're building an agent under the database, uh, business behind it, we know, okay, if something is a text property, 

00:24:10,399 --> 00:25:22,332 [Speaker 1]
we can constrain the LLM to only do like a certain set of operations against that. If something's a Boolean property, there's another set of operations that can be done. If something is a, um, integer or like a...... an array of strings or an array of INTs. There's effectively, like, a- an- a well-known set of API calls and operations that you can run against that. So what this means is, like, when we start the flow of the query engine, so your query comes in, gets routed to collections, and we start actually writing those queries, writing those aggregations. We can, like, present... T- we can, like, effectively present to the LLM for each field what the available options are. And because of that, because we can constrain the schema, we can also, like, know without executing ahead of time if a call is invalid. So, like, we can just not run... We can, like, ef- effectively, like, constrain this schema and constrain the structured outputs from the model to, like, always return valid, valid inputs for particular data types. So that really, that really saves you time because 

00:25:22,332 --> 00:26:09,112 [Speaker 1]
effectively you don't want... You don't... You wanna, like, avoid loops and retries as much as possible. Like, they are inevitable because there's, there's some things that aren't... Like, you can't know if s- a query with filters is gonna return results ahead of time, but there are some things you can know. So, like, you don't want to find yourself in a situation where you're running, you're running, like, queries or, like, sp- specific filter types against a database, only to find out after, like, running the LLM and running the ex- executing that query that it was actually an invalid combination. So the great thing here is we can kinda use the meta information that comes back from Weaviate to, to make sure that all... When we, when the LLM produces an output, that it will be valid. 

00:26:09,112 --> 00:26:46,512 [Speaker 0]
Yeah. It's, it's amazing. I mean, this kind of like structured outputs, like typing has solved text SQL, that's kind of how I think about it. Is you can type these things... I guess, like, I was sort of has-... When... I remember when, like, sort of with the Gorilla story when that first came out and they're like, "Oh, you have these function calling arguments." And I was like, "Ah, but why would the LLM follow the function calling?" So I was still kind of like, no text to GraphQL, but then this kind of wave of structured decoding constrained generation, and it's like, you can type it and then you get the schema from the database. And I... Like, for me, software engineering thing, when I first saw how you could create like a Pydantic model on the fly [laughs] and then you could throw that into the LLM. Yeah, that's, [laughs] that's a pretty cool- 

00:26:46,512 --> 00:26:53,752 [Speaker 1]
It is quite amazing. And, like, I've been amazed over, like, the last couple of months watching people like Dan on our team, just like how far they can take- 

00:26:53,752 --> 00:26:54,512 [Speaker 0]
[laughs] 

00:26:54,512 --> 00:27:28,692 [Speaker 1]
... the art, the artistry of like understanding, like, how to use things like Pydantic in, like, an expert manner. And, like, really make sure that, like, the... How fine grained that, that, like, um, constraining and schema constraining, like, works is just... Yeah, it's really impressive and it saves you so much time and it saves you so many errors. And, like, we had errors and then we would notice them in production and then just, just fix them because, because we had these like nice, nice model types and s- and stuff like that that you just alter and then the, the LLM just magically follows those. It's, it's really amazing. 

00:27:28,692 --> 00:27:56,241 [Speaker 0]
Yeah, I think, like, the way software engineers organize, like, validating data is also quite relevant to this agent thing with str- I, I guess, like, in addition to structured outputs, you also, like, kind of in the DSPy story, you had DSPy assertions. It's kind of like, uh, some, some outputs you can't, like, strictly type as well, and so you still maybe have like an LLM validation step. And yeah, that just kind of lesson of learning how software engineers organize that, like, validating data models [laughs]. Yeah, quite a deep one, that one. I guess, yeah- 

00:27:56,241 --> 00:28:14,331 [Speaker 1]
Yeah, like it's... It is kind of crazy just how, like, [sighs] like, the paradigm is so, like, still shifting and stuff like that. Like, when I first... Like, I remember years ago, like, before Weaviate working with, like, LLMs, and it's just at the end of your prompt, you would just have, like, a JSON representation of like, "Please, please return." 

00:28:14,331 --> 00:28:15,812 [Speaker 0]
[laughs] 

00:28:15,812 --> 00:29:06,192 [Speaker 1]
Like you, you... Begging, effectively, for it just to return something in, like, a specific format, and then you'd have to validate that when it came out. Like, yourself, you'd have to write that validation. And, like, just to see... Like, I, I mean, that's probably, like, the biggest trick that's made, like, agents such a success. Like, not like... Just in general, like, they made me believe in agents as well the last year or two, is just, like, how good structured outputs, tool calling, con- constrain- uh, constraint decoding. All of these things have worked because it's... Yeah, it's, it's just that, that's, that's probably... Like, that on top of, like, the model development. Like, how just the... How the models have improved has just made building agents such a feasible task now, because you just don't have to run all of this manual validation all the time. Because it's just so time constraining and so... It's like a house of cards. It's just really fragile. 

00:29:07,252 --> 00:29:37,092 [Speaker 0]
Yeah, amazing. Yeah, oh I absolutely love that topic. I think it's such an interesting one. And maybe the quick one, there is a paper, um, from Berkeley that came out recently about, like, designing, uh, agent-first data systems. Uh, sorry, I don't remember the exact title. [laughs] Uh, maybe something about like, um... Because you're always making these meta calls to get the schemas out to do this typing on the fly, do you think maybe you should... Like, the new database systems will, like, maybe cache that kind of inform... Do you think it will change, like, the structure of the database system to support that better? 

00:29:37,092 --> 00:29:42,232 [Speaker 1]
Yeah, like, it... That, that's a c- that's a good one because I think, like, 

00:29:42,232 --> 00:29:56,132 [Speaker 1]
yes, like, being able to cache that kind of stuff and have it, like, freely avai- freely, like, accessible, will make, make how the agent performs better. Like, for instance, and I know we've discussed this, like, at length, which is like, if 

00:29:56,192 --> 00:31:28,112 [Speaker 1]
Weaviate, you've got like text arrays and some people might use those as just like kind of, um, high cardinality text arrays, where it could be any, any type of value could appear in it. But very often what you see is that, like, when people are using like text array property types, what that really means is that, like, it's low cardinality and it's very likely some sort of categorical value. Like, it's a, it's a c- it's a categories type, type f- uh, property. So like, one thing we found is like...... if, if you can, like, do some meta-analysis of those categories, like, kind of ahead of time, or, or store those, well, then you make, like, the query, like, the Agent's zero shot ability to, like, answer those type, like questions being like, "Oh, um, find me..." I don't know, "Find me all the, the stocks in the last, you know, 12 months that have traded above X dollars." And then it can know, well, these are all the stocks available, so I could just search across each of those, um, in the last 12 months and filter by date or something like that. But I think things like that where there's, like, these little tricks that improve this. It's always around, like, the zero-shot ability, I think, of, like, the agent. So, like, you wanna... Like I said earlier, you wanna avoid having to do, like, a loop where it says, "Oh, we thought this value might exist in there," it doesn't. So, like, the more it can know upfront, the better. And, like, I think even, like, when we've been talking to users of the query agent the last couple of months, like, I think 

00:31:28,112 --> 00:33:21,612 [Speaker 1]
some of, like, the suggestions we make on, like, how you just initialize your collection have changed. Like, Weaviate's had this, like, description, uh, property, uh, available for, like, six years. And I, I chatted with Etienne about this. Like, we laugh, like, he, he laughs 'cause, like, I think he, they built it, like, s- six years ago, seven, like, whatev- whatever it is. Um, and, you know, people just generally don't want to type, uh, a, a long, lengthy description describing what a property does. You know, it's like all developers, you know, only write documentation if it's absolutely necessary so that there mi- they might not do that. But what we found is with the query agent, because it has access to the schema and all of the little meta properties attached to it, if you write some, like, kinda short descriptive property descriptions that explain what the purpose of that property is in your database, well, then the query agent says, "Oh, thank you. That's great. Now I know at runtime, like, what all of these properties are doing." You give me a little description about how to... What properties might appear in there, what they kind of look like, maybe they're... You know, I think Etienne had a use case where they were like, uh, you know, uh, country codes, like length two country codes. There's like a proper name for that, uh, standard, like it's an ISO standard. But effectively say- just so you know, all countries are allocated the, the, the two character country code format. So then when query agent sees that and then it knows, okay, when I'm, when I'm filtering on this field, I'm not gonna type in, like, Ireland, I'm gonna type in, like, IE or whatever the two country, two country code is. So little tricks like that help. And yeah, I think, like, what we've learned here is, like, maybe how people, like... People... You might, you might put in, like, a little bit of extra upfront effort when you create your collection or tables, whatever it is, but the, the payoff is that the agent is just able to navigate things a bit more seamlessly. 

00:33:21,612 --> 00:34:11,692 [Speaker 0]
Yeah, that's actually the best example I've ever heard of that. Like California, CA, as, like, an example of something that's hard to explicitly type. You're not gonna write a literal with the... Sorry, I'm doing US states because [laughs] that's what I could, I Okay. [laughs] But you're not gonna have, like, an enum with the 50 US states. In- instead you have that kind of thing, and yeah, that sort of property description. Yeah, it's also amazing. I, I guess, like, um, yeah, like, um, there's... I'm curious of that kind of, like, cardinality estimation. That's, like, a thing, uh, a big thing with relational databases. And I think this is a really interesting kinda theme in Weaviate, that Weaviate is adding more and more support for structured data. And I don't wanna, like... I know we have something that's coming but I don't wanna preview it. [laughs] But, but yeah, I do, I do think that's an interesting thing with Weaviate, and the evolution of it is going from, like, unstructured vector search engine to supporting more and more of database. 

00:34:11,692 --> 00:34:28,512 [Speaker 1]
Yeah, and, like, with that cardinality estimation stuff, you can effectively just treat it like a heuristic, which is like you say, "Okay, like, what's the size of my collection? Like, how many objects do I have?" And then you kinda say, "Okay, if something is... If there's only... If there's, like, 

00:34:28,512 --> 00:35:04,452 [Speaker 1]
10 values appearing X amount of times or something like that, we can kinda, you can kinda make a good decision as to whether this is, like, a high cardinality, like, column and not worth kind of saving information about because you won't get any nice filtering properties from it." Or you can kind of, like, test and say, "Oh, this looks... This, this appears to be that there's, like, a certain number of, uh, values appearing, like, only, like, a unique amount of times, so, like, they've crossed some sort of, sort of threshold to indicate that they're high cardinality. Let's remember this information effectively." 

00:35:04,452 --> 00:35:30,092 [Speaker 0]
Yeah, amazing. Well, also, I, I think this actually transitions perfectly just to talking about collection routing maybe a little bit further. Like, kind of, uh, yeah, just maybe how you see that kind of federated search within Weaviate and that sort of application. And maybe I have my books and then I have my papers, and there are two separate collections. Or maybe I have sort of my operational database and my analytical... Uh, like, my operational collection and my analytical collection. Like, just sort of how you think about collection routing. 

00:35:30,092 --> 00:37:06,868 [Speaker 1]
Yeah, I, I think this actually falls into a category of, like, something that I thought was kinda surprising, again, in how people use the query agent. Because, like, for me it was like... I thought it was, like, a nice to have in that you could have multiple, multiple collections and they might all be, like, very different and you just could run kinda like a federated search against them. And query agent will decide based on each collection, its schema, and what it knows about those, which is the relevant one. And I was like... You know, my initial thought was, "Oh, yeah, it'll pick the one that's relevant and it will just run queries against that." But actually what we see is some people, the way they, you know, they, they format their collections where there is, like, kind of, like, semantic joins between them. Like, they're, like, they're separate collections but there is crossover. So you might have, like, something about contracts and something about customers or something like that. But of course, customers have contracts. All, all of these types of things. All of these different, like, domain models that you can map.And what's really cool is, it kind of solves this problem in Weaviate where now users have this ability to... Whether it's ask or search mode, and it's probably even more powerful than search mode, where you can like run a query that you know needs to hit multiple collections and then get results back in like a single response format that like, is like interleaved between the two... Two or three collections. And like that's... I think that's actually very... That kind of tech- federated search is like really valuable to people in- in- in some ways that were kind of unexpected to me. Um, but like, again, I think the way that it works is, um, 

00:37:06,868 --> 00:37:44,087 [Speaker 1]
it's using the metadata we know about the collection, so every collection has a name. So hopefully that name is informative. Um, every collection has like a set of properties and- and values and types, data types associated to that. So part of that routing decision is to just like introspect, take a look at the collection names, take a look at like what those collections look like on the inside and make a decision as to whether, should this query hit just one of those? Or actually, is this question broad enough and like actually ambiguous enough that it- I w- it would benefit from just doing this across all collections or- or across a subset of them? 

00:37:44,087 --> 00:37:54,857 [Speaker 0]
Yeah, I think- I think sort of the... Yeah, the high level of the application is pretty clear. I- I guess like I'm- I'm just such a nerd that- that when you said semantic joins, [laughs] it just like lit up my brain and- 

00:37:54,857 --> 00:37:54,857 [Speaker 1]
Mm-hmm. 

00:37:54,857 --> 00:38:21,278 [Speaker 0]
... the first time I heard that term was, uh, when I had interviewed Madeleine Halse Boss, she works in like tabular intelligence and yeah, that kind of i- like, you don't need to explicitly, uh, link these tables with a foreign key reference. You can sort of just look at... And again, as we mentioned, we have the typing of the possible values for the columns and we can sort of do these joins on the fly between tables, I think. And then also it- you might not have exactly matched it, but you can use that LAI layer in the middle. 

00:38:21,278 --> 00:39:36,428 [Speaker 1]
And I think this is like what's in- interesting, like, you know, in- in- in... As part of the announcement, we kind of t- s- give a breakdown of the history of like database interfaces. But I think this is what's kind of exciting about, you know, not just what Weaviate is entering into right now, but where- where the world is kind of with agents and that you kind of... You... You might have had this concept of semantic joins, like, years ago. But it- it was still kind of hard to- to work around because at like, at run time and stuff like that, it's hard to figure out... You need... Kind of need a human in the loop to figure out, "Oh, like that's- that's about right." Or you could train a model to do it, but it's going to have an error rate. But now you just kind of have this magic agent in the middle that can observe what you're asking, observe what's available, and then s- look at the results and see, "Oh yeah, like that's a natural join." And it will like, do that join effectively at run time for you. Um, and it's really nice because, you know, yes, in classical databases in the past, y- you- you have like joins between tables and of course that... You could do that with Weaviate, you can key things and stuff like that. But it's also nice to have the ability to do that in kind of like a fuzzy, fuzzy manner as well. Um, so yeah, I think- I think it's just... It's really interesting, like what the... What the new interface to- to databases and data systems is nowadays. 

00:39:36,428 --> 00:40:03,448 [Speaker 0]
Yeah, amazing. Well yeah, so all... I think all that has just been amazing. Um, maybe if we could just... Maybe just kind of now zooming out a bit, but then also maybe sort of still staying pretty technical. But like... So these are kind of the... Some of the things that just generally go into the query agent. And then maybe talk... And then we talked about sort of with ask mode, you have these citations and, you know, this res-... We talked about the response model, but may- maybe we could also now talk about sort of newly introduced search mode and talk about sort of how that differs and... Yeah. 

00:40:03,448 --> 00:40:06,408 [Speaker 1]
Yeah, absolutely. So 

00:40:06,408 --> 00:42:42,240 [Speaker 1]
in short, search mode is ask mode without the... Without the- the answer generation at the end, but that's actually doing it a bit of a disservice because there's... Like, as we discovered, there's like a lot of work you need to- to do to make just the presentation of those results make sense. Um, so for me, the way I see it is like, ask mode is kind of designed for developers that are probably building something that's a bit end-to-end. So they want... They're like... They might, like, have their data in Weaviate and now want to build, like, an end-to-end application that will be consumed by... Like, so the developer user will build that for, like, end users. Um, so they'll... You ask a question, you get... And you get, like, your end-to-end answer or you have your con- conversational context in there. I think search mode is, like, designed for developers that, like, might not... They might be a bit, like, m- closer to like a- a more classic information retrieval problem. So it's like kind of closer to the DB in- in that sense, or like kind of DB problems. Um, so the i- the kind of... I think our core guiding light for developing search mode was like, well, if we're gonna build this, it has to be really... Like, have really good retrieval quality. It has to like be like- like understandably better than just doing like a hybrid search without filters and- and things like this. So the- the idea there was, okay, how do we squeeze the most performance and like, effectively give, like... Say to develop, like, the... I- I guess like the pitch to developers is, if you've got your d-... What... Your data in Weaviate, if you use search mode, you're gonna get expert information retrieval kind of, uh, techniques, learnings and industry know-how just applied to your data with one API call, just out of the box. You don't need to do anything. It will... The query agent will receive your query. It will, like, kind of p- put on any filters it sees. It will decompose your query if needed to... It will expand some of the terms if it thinks that would be valuable. And then it will give you back a set of search results that are like re-ranked in the context of your original answer. And, you know, ideally those answers should be much, much better than if you were to just run that query yourself without any kind of knowledge about w- how you sort of shaped it or whether it would have needed filters and stuff like that. And I think, like, what we found is like there's this really cool...We're- we're at this really cool stage where, you know, we started off with SQL in the '70s, 

00:42:42,240 --> 00:45:07,440 [Speaker 1]
pur- purely structured. Then you get to, like, ORMs and, uh, drivers and stuff like that. They make, like, the interface much more developer-friendly, but you're still dealing with, like, SQL under the hood, but really great, like, much more developer-friendly. Fast-forward to something like RAG, which is amazing, and you've got... Y- y- you like pretty much the, the inter- the language that users can talk to their data in is now pure, natural language. You can just say, you know, what is... Whatever your question is, you can just give it to the... You- you can give it to the, give it to the database, and the d- made it database will, like, semantically understand that. But not a silver bullet. There actually are some... There are some things from, like, the- the more structured world that people like, and that's things like filters and being able to ex- uh, extract certain kind of concrete rules that should be applied. And I think that's what search mode can kind of do is say, "Hey, you have... You have the, the semantic portion of your query, but there might be an intent in what you said, and a, and a field or property in your collection that matches," like a filter there, being like, "Find me some nice, uh, you know, summer shoes to wear o- on the beach that are less than, uh, $200," 'cause who's gonna be spending more than $200 on shoes like that? Um, and it might see, "Oh, there's, like, a price property here and that's in... marked in dollars, so let's make sure that there's a explicit filter there to filter below $200." And RAG can't really, you know, differentiate what numbers are, you know, vectors. They... Ta- that's just kind of beyond the scope of what they can represent, but they're great for the, the semantic portion of that query. So now with search mode you can extract the summer shoes, whatever, and then convert the price intent to a concrete filter. And all of this happens under the hood, and you just get back a set of search results. And, like... But just by definition, the retrieval quality on that is gonna be much better than doing, you know, BM25 vector or hybrid, just because you've reduced the search base down. You've done... You've done what is, like, fil- like, applying filters, like, just improves the search quality, but it's very hard to do at runtime, and it's very hard to ask developers to build applications that, like, can interpolate a query at runtime. But with search mode, that kind of just comes out of the box. 

00:45:07,440 --> 00:45:42,259 [Speaker 0]
Yeah, I- I love that. I think, yeah, f- just maybe just echoing what you said, that [laughs] sort of, like, um, text interface, I think that's why RAG became so popular out of the box, is a sort of, you know, companion with ChatGPT and with the early generation of LMS, and now sort of having this, like, text SQL layer solve- solves, so, like, how do I bring structured context? And then there's this interesting thing in the middle where it's, like, still, like, a search query, but you also get benefit from having a filter, but no- not so much structure. You have, like, a little bit of structure. It's, like, maybe cont- like, the canonical vector database schema is, like, content and then nothing else [laughs], like, e- everything else in a JSON 

00:45:42,259 --> 00:45:43,460 [Speaker 1]
Yeah [laughs]. 

00:45:43,460 --> 00:46:18,600 [Speaker 0]
[laughs]. Uh, yeah, and I guess, like, um... But I'm... There can be... Just one other thing, talking about these sort of search information retrieval pipelines, I'm just really excited to be sort of... Like, we kn- we know... I think everyone working in information retrieval knows that you can kind of over-fetch with a first-stage hybrid search, like, say, 50 candidates and then take it down to, say, 20 with, like, cross-encoders or list-wise re-ranking. And then, and then just once you open the box of these pipelines, there's all these things like query writing, query expansion, and then just, like, all this depth to queries. Like, even just the other day, I saw a survey paper just on query expansion [laughs], and so it's like... There's just all these things that you can do. 

00:46:18,600 --> 00:46:58,819 [Speaker 1]
Yeah, and I, I think that's what I really like about it, because, like, this is, like, how you do query expansion well or decomposition well, is like... This is, like, evolving research and changing over time. But the kind of the cool thing is, I, like, view this, like, the, like, the query agent in something like search mode in particular, it's like, we can just evolve that over time with the best practices as, as they change. Like, if, if a new piece of research just comes out saying, "This is the way to expand terms for, um, for queries," we could just apply that and, like, magically overnight the, the, the, the API can just get better overnight. Because, like, like I said, it's like 

00:46:58,819 --> 00:47:04,609 [Speaker 1]
in a way, you know, y- you've been working, like, incredibly hard on the, the benchmarking on this, right? 

00:47:04,609 --> 00:47:04,620 [Speaker 0]
Mm-hmm. 

00:47:04,620 --> 00:47:44,279 [Speaker 1]
And it's like, you know, we probably see results in, you know, search mode is, you know, X, X amount better than just doing pure hybrid. And, like, that's really cool, but it's also, like, not, not surprising. It's not like we're saying, you know, we've invented a new, a new BM25 or a new, like, dense vector or [laughs] ... sparse vector mode. It's like, no, what we've done is, like, we've applied the best practices from the industry and then kind of wrapped them up into this, into this API. So, like, that's why it's a compound system, but it's just super user-friendly to use. But that's why it, it performs, it performs well. So it's like we have this kind of living thing, um, that we can improve, uh, over time. 

00:47:44,279 --> 00:48:20,920 [Speaker 0]
Yeah, amazing. Yeah, it's so cool building that, like, agent layer on top of the search application that we have for sort of vector indexing, vector storage. I sort of hold out in thinking there are... I think search is, like, the biggest application of vector databases, but I sort of hold out in thinking there are definitely other interesting applications. Like, I really like it for population analysis. And I talked on the podcast with Martin Grudinders recently about, like, the catalog- like, cataloging data, and I think that kind of analyzing populations of data or novelty in AI or even these ideas about, like, putting the vector into the model inference. But yeah, I'm just really excited about... It's so cool having this, like, agent layer on top of an application that we know to enhance it and 

00:48:20,920 --> 00:48:21,049 [Speaker 1]
Oh, yeah. 

00:48:21,049 --> 00:48:21,220 [Speaker 0]
... get the 

00:48:21,220 --> 00:48:28,560 [Speaker 1]
Yeah. I mean, like, I think I've discussed this on this podcast a few times, so I- I can't not get a mention of graph factors. It- 

00:48:28,560 --> 00:48:28,569 [Speaker 0]
[laughs] 

00:48:28,569 --> 00:48:49,548 [Speaker 1]
... again, because it seems to be [laughs] ... Michael too, but, like, any- anything you can model as a vector effectively benefits from being pumped into a vector database, especially once you're at scale. So if you, if you've got a big representation of graphs that are, like, you've tuned into looking like embeddings, well, then...... get those hundred, you know, what might be, like, proteins or something from that world- 

00:48:49,548 --> 00:48:50,138 [Speaker 0]
[laughs] Wow 

00:48:50,138 --> 00:49:11,807 [Speaker 1]
... represented as vectors. You can search across them and find, like, novel discoveries and, you know, link prediction, all of these ty- types of cool things that you can do. So, yeah, there, s- search is a very natural, like, and obvious functionality, but the, all the, all the benefits and things that we've built extend beyond that too if, if that's your use case. 

00:49:11,808 --> 00:49:35,747 [Speaker 0]
Yeah, amazing. Yeah, and the, the multimodal thing is all just super amazing, yeah. Amazing. So, uh, maybe sort of, like, pivoting out, I think that was an awesome deep dive into tech. I just really enjoyed talking about that. But, um, maybe if we could just kinda talk a little more about the GA release of the Query Agent, sort of just setting the stage of where we're at. Um, I think the integration with the cloud console is awesome. I, I love it personally, and it, maybe if you could just kinda describe the journey of that and then, and then, yeah, we'll just... 

00:49:35,747 --> 00:51:44,008 [Speaker 1]
Yeah, absolutely. So, like, the, the Query Agent, like, was first and foremost designed as, like, a, like a, like a client SDK or through an API, so we... It's available obviously for Python and TypeScript right now. Um, but of course, we have this great cloud product and console where we want users to be able to get a taste of what the, the Query Agent is. And, you know, if someone's... The- there are almost, like, two types of users. If someone's using the Query Agent through code, they might have, like, they might have, like, an application that they've, like, deployed to production that's, you know, running regularly on a certain cadence or, or something like that. But there's also this other type of user that comes to the console, and they just want to engage with their Weaviate data. Like, they've, they've spent the time crafting a collection, getting their data in. There's, of course, GraphQL, and that's one way you can interact with your database. But maybe they just wanna say, like, "I just wanna talk to my data and get, like, an understanding of how Weaviate works." And I think that's, like, a really nice feature of what the Query Agent does in the console. It means, it kinda gives, it gives users the ability just to get data in and just start getting value out of Weaviate. Maybe, like, ask a couple of questions and see, "Oh, like, I should... I just and created a property for my collection, and I tagged it as a string, but it's actually a number or it's a date. I would have benefited from making that, like, a, a concrete data type, like, that matches what it actually is." So they might go back and reformulate their collection, rebuild it, and, you know, change, change the date, uh, data types or something like that. And I think just having that, like, back and forth with your data, um, should add a lot of value for, for users. And you can do aggregates, so you can say, "Look, how many objects do I have?" Um, it means that kind of the non, like, the pe- people that didn't create the data or, like, import it into Weaviate can also engage with it and, like, get a, get a sense, sense of what's in there. Um, so my hope is that it kind of enables, um, users to interact with their data in just a more user-friendly and, and maybe in some, like, novel ways as well. 

00:51:44,008 --> 00:51:57,607 [Speaker 0]
Yeah, it's... I mean, it's so cool. It's so fun to use. And maybe even just talking, like, giving shout-outs to, like, Paul and David and Jaro and Jolanta and all the, everyone working, uh, uh, just this kind of, like, GUI console for the database. 

00:51:57,607 --> 00:51:59,028 [Speaker 1]
Yeah, I mean, like- 

00:51:59,028 --> 00:51:59,048 [Speaker 0]
Okay? 

00:51:59,048 --> 00:53:04,268 [Speaker 1]
Yeah, like, we, we was... Spoke about it at the start, but, like, the... It was so cool just to see the enthusiasm. Like, we had built this as an API, and I, I think once we had the TypeScript, TypeScript, uh, client, there was such enthusiasm from, uh, the entire, like, product and, like, cloud team. Like, Paul, Jaro, David, all, e- everyone, just to be like, "Oh, how do we, how do we get this into the console?" Because, like, they saw it was, like, giving them value for, like, you know, when they're testing out new features in Weaviate and new features in the console, being like, "Well, this..." They thought it was cool, so they were, like, really, just really positive around, um, adding it to, to the console. So I was obviously more than happy to help because, again, it's just really good feedback to get because, you know, uh, I love, I love when I hear of people in Weaviate just using, using it and, like, dogfooding the product because it's... And, like, giving me honest feedback as well. Being like, "Hey, I, I don't... I'm gonna use the, this, this method or this part of the API, but I don't think it's very user-friendly," and stuff like that. And I love hearing that because you can make the change, you can make the changes, and it's very hard to make changes when you don't know what's not working, right? 

00:53:04,268 --> 00:53:16,328 [Speaker 0]
[laughs] Yeah, yeah, no, I, I also really love the explorer. Like, as much as I've been going through, like, the BIR data, doing all these, the search benchmark, I love just clicking through the explorer to just see [laughs] the datasets better. 

00:53:16,328 --> 00:54:06,908 [Speaker 1]
Yeah, it's amazing. Like, pretty, like, I have this new flow now when, like, I'm testing new features with the Query Agent, which is, like, we can have it deployed, and I can now write the zero code. I can just go to the console. I can import my data from a CSV I have. I can create all my properties, mark which ones I want vectorized. I can import that. Uses our own embedding service, so that's super fast. Gets the data in. It's already pre-vectorized. No API key is needed. I can then go to the explorer console, have a look at the data, say, "Yep, that meets my expectations." And then I can go straight to the agents tab and just try, try the Query Agent and just start talking with my data. And let's say I push something that changes how we do filtering or something that changes how we write the answers or something like that. I can, like, kind of immediately validate whether that has worked or not. 

00:54:06,908 --> 00:54:06,948 [Speaker 0]
Yeah, that's a- [laughs] 

00:54:06,948 --> 00:54:08,428 [Speaker 1]
No code. 

00:54:08,428 --> 00:54:30,808 [Speaker 0]
[laughs] Yeah, that is super interesting, and I, I didn't know that you... I love learning these little nuggets about what you can do with Weaviate, with the... I didn't know you could mark the columns with the CSV import, so, yeah, I'll definitely have to... [laughs] Yeah, I'll see, like, a conversation in Slack about some feature in Weaviate that will be, like, six months ago or something, and then I'll comment like, "Thank you." [laughs] Like, "You guys updated this, and it's..." But yeah, it's always- 

00:54:30,808 --> 00:54:38,147 [Speaker 1]
And so fast. It's- it's what happens when you have a lot of great people working very, very hard to, like, release new features all the time. 

00:54:38,147 --> 00:54:51,147 [Speaker 0]
Yeah, amazing. Uh, awesome. So, I, I think, um, maybe, kind of, I know we're kinda coming up on the hour, so I'll try to pack, pack these questions in. But, um, maybe talking a little bit about the, sort of, Medabuddy case study and just, yeah, your experience with, with that.

00:54:51,332 --> 00:56:23,432 [Speaker 1]
Yeah, so we had, me- met everybody who was one of the earliest users of, of, um, the Query Agent. And it was just... They were so useful, 'cause they're a really in- really interesting use case around effectively, like, uh, having this personal assistant that, like, tracks, like, your fitness and your nutrition and stuff like that. And the reason I really, like, latched onto this use case and found, found it really great to work with was because the data, the data inside of those collections was, like, you know, very, like, structured in that sense. You know, there's, like, meals. There's nutrition. There's exercises, all of these things. So I, I... It was a really good testing bed to see how good the, the, the Query Agent's, um, filtering capabilities were, and, like, abilities to do gre- aggregations and date filtering and all of these types of things. We, we were able to really, like, fine-tune and, like, discover what the failure modes were and discover where it was working well, and saw, you know, that it being a chat application would work better and stuff like that. So they were great, great, really great to work with. They just gave, like, really, really great feedback. And like I said, I loved, loved the use case, 'cause it was, like, kind of exactly where I wanted to see the Query Agent shine, which is, like, you've got all of this in, like... You... This, this collection is really well-structured. You've got all of the data and, like, uh, information around the data types available to you. Like, go make the most out of this. Um, and I think, I think it, you know, it has been a success for them, and it has shown... Like, kind of saved them a lot of development time and improved engagement and stuff like that with their application. 

00:56:23,432 --> 00:56:32,792 [Speaker 0]
Yeah, and, uh, I love the query that, uh, uh, is qua- uh, sorry, I'm blurring. The r- release post will be... This'll be pub- [laughs] This will, I guess, will be published after that. So I can just say it now. 

00:56:32,792 --> 00:56:32,811 [Speaker 1]
Cool. 

00:56:32,812 --> 00:56:56,212 [Speaker 0]
But, uh, the, the query of, um, "Show my protein-heavy dinners under 600 calories last week and how they affected recovery," I love that. For me, one thing that instantly jumps out about that is the collection routing, 'cause you might have the dinner log and then you also have the articles on, "How does that affect recovery?" So that's, like, the kind of canonical vector searching thing, is you've got all the scientific papers on [laughs] pr- pro- recovering from workouts. Yeah. 

00:56:56,212 --> 00:58:06,512 [Speaker 1]
Exactly, and, like, you know, you look at that question, that, like, that query you just asked, and you can kind of, like, start to extract... You can, you can kind of in your head map what the semantic aspect of that is to what the structured part is. You know, so, prot- protein-heavy dinners is probably, like, a semantic query you might send into, like, uh, a nutrition collection or something that includes, like, kinda meals you've eaten. But, like, 600 calories last week. That's, that's... Like, 600 calories, like, you know... Okay, if the data, if the data is, like, saying this meal was X amount of calories, you can, you can actually filter on that in a structured manner. And if you look at something like last week, well, then if you just make the agent aware of what date today is, it can say, "Okay, I'm... This user has given me a window. I know what the window I should be looking in." So that's two filters, like, that you can extract. Like, a human can extract from your head being like, "This is how I would approach this. If I were to, like, spend the time writing the Weaviate filters for this question, I would, like, make this the semantic query and this the structured part." So, that's, that's why it was really cool, because I... It was a great testing bed, like I said, for those types of questions. 

00:58:06,512 --> 00:58:27,332 [Speaker 0]
Yeah, amazing. Uh, yeah, so, s- sort of a question I like to anchor the podcast with is what directions excite you the most for the future of AI? But I guess, Charles, you'll have to answer that one when you return for your six and a half [laughs] half. I just wrote a half. Yeah. Of course, on the podcast but... [laughs] So, for this, for this podcast particularly, um, what directions for the future of the Query Agent excite you the most? 

00:58:27,332 --> 00:58:39,092 [Speaker 1]
Yeah, like, I think... The... I, I think, like, what I see with the Query Agent is, like, first and foremost, it's like the directions are 

00:58:39,092 --> 01:00:38,412 [Speaker 1]
paying attention to how our users are using it and wh- what's missing in the future. So we added this new mode, so I, I'm very interested to see do some new modes that users want to utilize, like, just pop up as organic use cases over time. Like, I don't know how the things change so fast. In the next year, there might be some new paradigm or something like that that emerges. So I'm like, "What, what new kind of cool mode might, uh, pop up?" Ma- whether it's using other tools or, or something like this, or even just having like a really deep, deep thinking mode that, where you... Maybe it's like users are happy to really let this agent just run over Weaviate for a while, kinda like this deep research stuff that you see and say, "Okay, I'm just gonna... Give me 10 minutes just to, like, work over your data, work over the database and come back to you with something really interesting." So, that, that's really interesting to me to see if we have this kind of loopy, um, research mode in there with, with, with the Query Agent. But, I think more broadly than is this idea of, like, memory has really been, like, coming up a lot lately. Um, and it's not just, like, the Query Agent. It's, like, for anyone building with Agents or building with Conversations and stuff like that. It's like, what is, what is the function of, like, memory and, like, memory for both Agents and for, for users to, like, improve the... How these systems operate over time? Like, is it the unlock that, that kind of allows for, like, what you would previously maybe call, like, online training and just, like, uh, kind of self-improvement over time? And I, I think it might be. I think, I think probably where some Agents are failing in, in production or like out in the wild is that there's just, like, a lack of continuity. And it's not just Agents; it's also just Conversations. Like, I think people... The expectations that people have from these systems now is that if it makes a mistake, it should learn from that and it should, like, remember that. Um, and it shouldn't make it again. And I think memory is just, like- 

01:00:38,412 --> 01:00:38,422 [Speaker 0]
Yeah 

01:00:38,422 --> 01:01:17,192 [Speaker 1]
... more and more you're hearing about it. You're hearing about, hearing about it in the context of whether it's chat applications or you're hearing about it in the context of, like, these deep kind of, uh, agentic systems, whether it's like booking systems and stuff like that, storing user preferences, whatever it might be. But it seems like memory is like a really powerful way to, to solve a lot of these problems, and I think it just has such a natural crossover with, with vector databases and a store of value. Like, can, can a vector database make memory more efficient? And, like, are, are there whole new infrastructure changes that can be made to, to make memory work at scale? 

01:01:17,192 --> 01:01:30,332 [Speaker 0]
Yeah, amazing. Well, Charles, thanks so much for joining the podcast. Congratulations on the GA release of the Query Agent. It's been such a fun conversation, and I really hope it inspires people to check out the Query Agent and just generally be excited about Weaviate. Charles, thanks so much. 

01:01:30,332 --> 01:01:31,932 [Speaker 1]
Yeah. Thank you, Connor. Thanks.